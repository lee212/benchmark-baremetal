{
    "cmds": [
        "/usr/bin/hadoop fs -rm -r -skipTrash /Terasort/Input", 
        "/usr/bin/hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen -Ddfs.replication=1 -Ddfs.client.block.write.locateFollowingBlock.retries=15 -Dyarn.app.mapreduce.am.job.cbd-mode.enable=false -Ddfs.blocksize=536870912 -Dmapreduce.map.java.opts=-Xms3048m -Xmx3048m -Dyarn.app.mapreduce.am.job.map.pushdown=false -Dmapreduce.job.maps=612 -Dmapreduce.map.memory.mb=3814 %(num_rows)s /Terasort/Input",
        "/usr/bin/hadoop fs -rm -r -skipTrash /Terasort/Output", 
        "/usr/bin/hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar terasort -Dmapreduce.job.reduce.shuffle.consumer.plugin.class=org.apache.hadoop.mapreduce.task.reduce.Shuffle -Ddfs.client.block_write.locateFollowingBlock.retries=30 -Dmapred.reduce.child.log.level=WARN -Ddfs.replication=1 -Ddfs.blocksize=536870912 -Dmapreduce.map.java.opts=-Xms3048m -Xmx3048m -Dmapreduce.reduce.java.opts=-Xms3048m -Xmx3048m -Dyarn.app.mapreduce.am.job.cbd-mode.enable=false -Dyarn.app.mapreduce.am.job.map.pushdown=false -Dmapreduce.job.maps=612 -Dmapreduce.job.reduces=612 -Dmapreduce.reduce.memory.mb=3814 /Terasort/Input /Terasort/Output"
    ], 
    "size": {
        "bigdata": {
		"num_rows": 6000000000
        }, 

        "gigantic": {
		"num_rows": 3200000000
        }, 

        "huge": {
		"num_rows": 320000000
        }, 

	"large": {
		"num_rows": 32000000 
        }, 

        "small": {
		"num_rows": 3200000
        }, 
        "tiny": {
		"num_rows": 32000
        }
    }
}
