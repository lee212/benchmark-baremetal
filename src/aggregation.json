{
    "cmds": [
        "/usr/bin/hadoop fs -rm -r -skipTrash /Aggregation/Input", 
        "/usr/bin/hadoop jar /var/lib/hadoop-hdfs/autogen-7.1-SNAPSHOT-jar-with-dependencies.jar HiBench.DataGen -t hive -b /Aggregation -n Input -m %(mappers)s -r %(reducers)s -p %(pages)s -v %(uservisits)s -o sequence",
	"/usr/bin/hadoop fs -rm -r -skipTrash /Aggregation/Output", 
	"hive -f ~/uservisits_aggre.hive",
	"spark-submit --class com.intel.hibench.sparkbench.sql.ScalaSparkSQLBench --master yarn-client --num-executors %(executors)s --executor-cores %(e_cores)s --executor-memory %(e_mem)s /var/lib/hadoop-hdfs/sparkbench-assembly-7.1-SNAPSHOT-dist.jar ScalaAggregation ~/uservisits_aggre.hive"
    ], 
    "size": {
        "bigdata": {
		"mappers": "{{os.environ['B_VAR_VCORES']}}",
		"reducers": "{{os.environ['B_VAR_VCORES']}}",
		"pages": 100000000,
		"uservisits": 1000000000,
		"executors": "{{int(os.environ['B_VAR_VCORES']) * int(os.environ['B_VAR_WORKERS']) / 5.3 // 1}}",
		"e_cores": 5,
		"e_mem": "{{float(os.environ['B_VAR_MEM']) / int(os.environ['B_VAR_VCORES']) * 4.8 // 1}}g"
        }
    }
}
